{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MLP Basics\n",
    "Vanilla neural networks (i.e., Multilayer perceptrons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models: https://keras.io/models/sequential/\n",
    "layers: https://keras.io/layers/core/\n",
    "optimizers: https://keras.io/optimizers/\n",
    "losses: https://keras.io/losses/\n",
    "metrics: https://keras.io/metrics/\n",
    "weight initilization: https://keras.io/initializers/\n",
    "activation functions: https://keras.io/activations/\n",
    "dropout: https://keras.io/layers/core/#dropout\n",
    "normalization: https://keras.io/layers/normalization/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Structures\n",
    "- Each MLP model is consisted of one input layer, several hidden layers, and one output layer\n",
    "- Number of neurons in each layer is not limited\n",
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net.jpeg\" style=\"width: 300px\"/>\n",
    "<br>\n",
    "<center>**MLP with one hidden layer**</center>\n",
    "- Number of input neurons: 3\n",
    "- Number of hidden neurons: 4\n",
    "- Number of output neurons: 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Regression Task (Boston Housing Prices)\n",
    "- When the target (**y**) is continuous (real)\n",
    "- For loss function and evaluation metric, mean squared error (MSE) is commonly used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "- Boston housing dataset has total 506 data instances (404 training & 102 test)\n",
    "- 13 attributes (features) to predict \"the median values of the houses at a location\"\n",
    "- Doc: https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(404,)\n",
      "(102, 13)\n",
      "(102,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "models: https://keras.io/models/sequential/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Model Layers\n",
    "layers: https://keras.io/layers/core/ weight initilization: https://keras.io/initializers/ activation functions: https://keras.io/activations/ dropout: https://keras.io/layers/core/#dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras model with two hidden layer with 10 neurons each\n",
    "model.add(Dense(10, input_shape=(13,)))   # Input layer => input_shape should be explicitly designated\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(10))                      # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(10))                      # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.add(Dense(1))                       # Output layer => output dimension = 1 since it is regression problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Model Compile (with optimizer)\n",
    "optimizers: https://keras.io/optimizers/ \n",
    "losses: https://keras.io/losses/\n",
    "metrics: https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(learning_rate=0.01, momentum=0.0)\n",
    "model.compile(optimizer=sgd, loss='mean_squared_error', metrics=['mse'])  # for regression problems, mean squared error (MSE) is often employed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 371\n",
      "Trainable params: 371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Model Fit (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples\n",
      "Epoch 1/100\n",
      "404/404 [==============================] - 1s 1ms/sample - loss: 365.5055 - mse: 365.5055\n",
      "Epoch 2/100\n",
      "404/404 [==============================] - 0s 49us/sample - loss: 102.3870 - mse: 102.3870\n",
      "Epoch 3/100\n",
      "404/404 [==============================] - 0s 52us/sample - loss: 83.8280 - mse: 83.8280\n",
      "Epoch 4/100\n",
      "404/404 [==============================] - 0s 50us/sample - loss: 84.1185 - mse: 84.1185\n",
      "Epoch 5/100\n",
      "404/404 [==============================] - 0s 56us/sample - loss: 84.0177 - mse: 84.0177\n",
      "Epoch 6/100\n",
      "404/404 [==============================] - 0s 89us/sample - loss: 82.6715 - mse: 82.6715\n",
      "Epoch 7/100\n",
      "404/404 [==============================] - 0s 75us/sample - loss: 82.8856 - mse: 82.8856\n",
      "Epoch 8/100\n",
      "404/404 [==============================] - 0s 46us/sample - loss: 81.4509 - mse: 81.4509\n",
      "Epoch 9/100\n",
      "404/404 [==============================] - 0s 60us/sample - loss: 80.3800 - mse: 80.3800\n",
      "Epoch 10/100\n",
      "404/404 [==============================] - 0s 49us/sample - loss: 81.1025 - mse: 81.1025\n",
      "Epoch 11/100\n",
      "404/404 [==============================] - 0s 52us/sample - loss: 79.7856 - mse: 79.7856\n",
      "Epoch 12/100\n",
      "404/404 [==============================] - 0s 56us/sample - loss: 78.1310 - mse: 78.1310\n",
      "Epoch 13/100\n",
      "404/404 [==============================] - 0s 128us/sample - loss: 78.8671 - mse: 78.8671\n",
      "Epoch 14/100\n",
      "404/404 [==============================] - 0s 54us/sample - loss: 81.7580 - mse: 81.7580\n",
      "Epoch 15/100\n",
      "404/404 [==============================] - 0s 109us/sample - loss: 82.4526 - mse: 82.4526\n",
      "Epoch 16/100\n",
      "404/404 [==============================] - 0s 72us/sample - loss: 84.0010 - mse: 84.0010\n",
      "Epoch 17/100\n",
      "404/404 [==============================] - 0s 80us/sample - loss: 82.7942 - mse: 82.7942\n",
      "Epoch 18/100\n",
      "404/404 [==============================] - 0s 55us/sample - loss: 81.5902 - mse: 81.5902\n",
      "Epoch 19/100\n",
      "404/404 [==============================] - 0s 62us/sample - loss: 82.4961 - mse: 82.4961\n",
      "Epoch 20/100\n",
      "404/404 [==============================] - 0s 55us/sample - loss: 81.7781 - mse: 81.7781\n",
      "Epoch 21/100\n",
      "404/404 [==============================] - 0s 51us/sample - loss: 81.0154 - mse: 81.0154\n",
      "Epoch 22/100\n",
      "404/404 [==============================] - 0s 48us/sample - loss: 82.6459 - mse: 82.6459\n",
      "Epoch 23/100\n",
      "404/404 [==============================] - 0s 43us/sample - loss: 81.3487 - mse: 81.3487\n",
      "Epoch 24/100\n",
      "404/404 [==============================] - 0s 42us/sample - loss: 80.5575 - mse: 80.5575\n",
      "Epoch 25/100\n",
      "404/404 [==============================] - 0s 82us/sample - loss: 81.0042 - mse: 81.0042\n",
      "Epoch 26/100\n",
      "404/404 [==============================] - 0s 54us/sample - loss: 81.0594 - mse: 81.0594\n",
      "Epoch 27/100\n",
      "404/404 [==============================] - 0s 47us/sample - loss: 81.4313 - mse: 81.4313\n",
      "Epoch 28/100\n",
      "404/404 [==============================] - 0s 54us/sample - loss: 80.1268 - mse: 80.1268\n",
      "Epoch 29/100\n",
      "404/404 [==============================] - 0s 56us/sample - loss: 81.7455 - mse: 81.7455\n",
      "Epoch 30/100\n",
      "404/404 [==============================] - 0s 62us/sample - loss: 83.5390 - mse: 83.5390\n",
      "Epoch 31/100\n",
      "404/404 [==============================] - 0s 62us/sample - loss: 79.9905 - mse: 79.9905\n",
      "Epoch 32/100\n",
      "404/404 [==============================] - 0s 50us/sample - loss: 80.2129 - mse: 80.2129\n",
      "Epoch 33/100\n",
      "404/404 [==============================] - 0s 60us/sample - loss: 78.9422 - mse: 78.9422\n",
      "Epoch 34/100\n",
      "404/404 [==============================] - 0s 45us/sample - loss: 79.0374 - mse: 79.0374\n",
      "Epoch 35/100\n",
      "404/404 [==============================] - 0s 76us/sample - loss: 79.5748 - mse: 79.5748\n",
      "Epoch 36/100\n",
      "404/404 [==============================] - 0s 64us/sample - loss: 78.3011 - mse: 78.3011\n",
      "Epoch 37/100\n",
      "404/404 [==============================] - 0s 61us/sample - loss: 78.5239 - mse: 78.5239\n",
      "Epoch 38/100\n",
      "404/404 [==============================] - 0s 62us/sample - loss: 78.6260 - mse: 78.6260\n",
      "Epoch 39/100\n",
      "404/404 [==============================] - 0s 67us/sample - loss: 78.0113 - mse: 78.0113\n",
      "Epoch 40/100\n",
      "404/404 [==============================] - 0s 58us/sample - loss: 77.9661 - mse: 77.9661\n",
      "Epoch 41/100\n",
      "404/404 [==============================] - 0s 52us/sample - loss: 79.0416 - mse: 79.0416\n",
      "Epoch 42/100\n",
      "404/404 [==============================] - 0s 36us/sample - loss: 79.2180 - mse: 79.2180\n",
      "Epoch 43/100\n",
      "404/404 [==============================] - 0s 59us/sample - loss: 79.2106 - mse: 79.2106\n",
      "Epoch 44/100\n",
      "404/404 [==============================] - 0s 50us/sample - loss: 78.0101 - mse: 78.0101\n",
      "Epoch 45/100\n",
      "404/404 [==============================] - 0s 40us/sample - loss: 79.9921 - mse: 79.9921\n",
      "Epoch 46/100\n",
      "404/404 [==============================] - 0s 53us/sample - loss: 78.8048 - mse: 78.8048\n",
      "Epoch 47/100\n",
      "404/404 [==============================] - 0s 67us/sample - loss: 79.3189 - mse: 79.3189\n",
      "Epoch 48/100\n",
      "404/404 [==============================] - 0s 62us/sample - loss: 79.1597 - mse: 79.1597\n",
      "Epoch 49/100\n",
      "404/404 [==============================] - 0s 56us/sample - loss: 78.2788 - mse: 78.2788\n",
      "Epoch 50/100\n",
      "404/404 [==============================] - 0s 56us/sample - loss: 79.0529 - mse: 79.0530\n",
      "Epoch 51/100\n",
      "404/404 [==============================] - 0s 70us/sample - loss: 77.9707 - mse: 77.9707\n",
      "Epoch 52/100\n",
      "404/404 [==============================] - 0s 93us/sample - loss: 77.5849 - mse: 77.5849\n",
      "Epoch 53/100\n",
      "404/404 [==============================] - 0s 88us/sample - loss: 78.0965 - mse: 78.0965\n",
      "Epoch 54/100\n",
      "404/404 [==============================] - 0s 52us/sample - loss: 78.2456 - mse: 78.2456\n",
      "Epoch 55/100\n",
      "404/404 [==============================] - 0s 65us/sample - loss: 79.2623 - mse: 79.2623\n",
      "Epoch 56/100\n",
      "404/404 [==============================] - 0s 47us/sample - loss: 79.1784 - mse: 79.1784\n",
      "Epoch 57/100\n",
      "404/404 [==============================] - 0s 52us/sample - loss: 78.1220 - mse: 78.1220\n",
      "Epoch 58/100\n",
      "404/404 [==============================] - 0s 60us/sample - loss: 77.6840 - mse: 77.6840\n",
      "Epoch 59/100\n",
      "404/404 [==============================] - 0s 61us/sample - loss: 77.6569 - mse: 77.6569\n",
      "Epoch 60/100\n",
      "404/404 [==============================] - 0s 43us/sample - loss: 77.5094 - mse: 77.5094\n",
      "Epoch 61/100\n",
      "404/404 [==============================] - 0s 46us/sample - loss: 77.4735 - mse: 77.4735\n",
      "Epoch 62/100\n",
      "404/404 [==============================] - 0s 43us/sample - loss: 78.8837 - mse: 78.8837\n",
      "Epoch 63/100\n",
      "404/404 [==============================] - 0s 36us/sample - loss: 77.1736 - mse: 77.1736\n",
      "Epoch 64/100\n",
      "404/404 [==============================] - 0s 37us/sample - loss: 78.5169 - mse: 78.5169\n",
      "Epoch 65/100\n",
      "404/404 [==============================] - 0s 40us/sample - loss: 77.4512 - mse: 77.4512\n",
      "Epoch 66/100\n",
      "404/404 [==============================] - 0s 47us/sample - loss: 77.3881 - mse: 77.3881\n",
      "Epoch 67/100\n",
      "404/404 [==============================] - 0s 39us/sample - loss: 77.9785 - mse: 77.9785\n",
      "Epoch 68/100\n",
      "404/404 [==============================] - 0s 44us/sample - loss: 77.4714 - mse: 77.4714\n",
      "Epoch 69/100\n",
      "404/404 [==============================] - 0s 48us/sample - loss: 77.3733 - mse: 77.3733\n",
      "Epoch 70/100\n",
      "404/404 [==============================] - 0s 46us/sample - loss: 77.6528 - mse: 77.6528\n",
      "Epoch 71/100\n",
      "404/404 [==============================] - 0s 49us/sample - loss: 77.3107 - mse: 77.3107\n",
      "Epoch 72/100\n",
      "404/404 [==============================] - 0s 45us/sample - loss: 78.9830 - mse: 78.9830\n",
      "Epoch 73/100\n",
      "404/404 [==============================] - 0s 43us/sample - loss: 77.3188 - mse: 77.3188\n",
      "Epoch 74/100\n",
      "404/404 [==============================] - 0s 34us/sample - loss: 78.3565 - mse: 78.3565\n",
      "Epoch 75/100\n",
      "404/404 [==============================] - 0s 42us/sample - loss: 79.5602 - mse: 79.5602\n",
      "Epoch 76/100\n",
      "404/404 [==============================] - 0s 38us/sample - loss: 77.6957 - mse: 77.6957\n",
      "Epoch 77/100\n",
      "404/404 [==============================] - 0s 33us/sample - loss: 78.0276 - mse: 78.0276\n",
      "Epoch 78/100\n",
      "404/404 [==============================] - 0s 41us/sample - loss: 77.5121 - mse: 77.5121\n",
      "Epoch 79/100\n",
      "404/404 [==============================] - 0s 37us/sample - loss: 77.3640 - mse: 77.3640\n",
      "Epoch 80/100\n",
      "404/404 [==============================] - 0s 38us/sample - loss: 76.9276 - mse: 76.9276\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 53us/sample - loss: 77.6393 - mse: 77.6393\n",
      "Epoch 82/100\n",
      "404/404 [==============================] - 0s 42us/sample - loss: 77.4259 - mse: 77.4259\n",
      "Epoch 83/100\n",
      "404/404 [==============================] - 0s 41us/sample - loss: 77.4949 - mse: 77.4949\n",
      "Epoch 84/100\n",
      "404/404 [==============================] - 0s 47us/sample - loss: 77.3322 - mse: 77.3322\n",
      "Epoch 85/100\n",
      "404/404 [==============================] - 0s 39us/sample - loss: 77.4082 - mse: 77.4082\n",
      "Epoch 86/100\n",
      "404/404 [==============================] - 0s 53us/sample - loss: 77.2768 - mse: 77.2768\n",
      "Epoch 87/100\n",
      "404/404 [==============================] - 0s 44us/sample - loss: 77.3745 - mse: 77.3745\n",
      "Epoch 88/100\n",
      "404/404 [==============================] - 0s 49us/sample - loss: 77.2202 - mse: 77.2203\n",
      "Epoch 89/100\n",
      "404/404 [==============================] - 0s 35us/sample - loss: 77.5726 - mse: 77.5726\n",
      "Epoch 90/100\n",
      "404/404 [==============================] - 0s 41us/sample - loss: 78.1099 - mse: 78.1099\n",
      "Epoch 91/100\n",
      "404/404 [==============================] - 0s 39us/sample - loss: 78.0194 - mse: 78.0194\n",
      "Epoch 92/100\n",
      "404/404 [==============================] - 0s 40us/sample - loss: 78.2259 - mse: 78.2259\n",
      "Epoch 93/100\n",
      "404/404 [==============================] - 0s 40us/sample - loss: 77.3382 - mse: 77.3382\n",
      "Epoch 94/100\n",
      "404/404 [==============================] - 0s 43us/sample - loss: 77.1060 - mse: 77.1060\n",
      "Epoch 95/100\n",
      "404/404 [==============================] - 0s 49us/sample - loss: 77.2610 - mse: 77.2610\n",
      "Epoch 96/100\n",
      "404/404 [==============================] - 0s 38us/sample - loss: 77.2613 - mse: 77.2613\n",
      "Epoch 97/100\n",
      "404/404 [==============================] - 0s 45us/sample - loss: 77.3706 - mse: 77.3706\n",
      "Epoch 98/100\n",
      "404/404 [==============================] - 0s 63us/sample - loss: 78.3441 - mse: 78.3441\n",
      "Epoch 99/100\n",
      "404/404 [==============================] - 0s 43us/sample - loss: 77.5374 - mse: 77.5374\n",
      "Epoch 100/100\n",
      "404/404 [==============================] - 0s 55us/sample - loss: 77.5204 - mse: 77.5204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13d563550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=50, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Model Evaluate\n",
    "metrics: https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "102/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 947us/sample - loss: 118.5875 - mse: 77.9206\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mse']\n",
      "[77.92059565525429, 77.92059]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)     # list of metric names the model is employing\n",
    "print(results)                 # actual figure of metrics computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  77.92059565525429\n",
      "mse:  77.92059\n"
     ]
    }
   ],
   "source": [
    "print('loss: ', results[0])\n",
    "print('mse: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clear the model (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Binary Classification Task (Breast Cancer)\n",
    "- When the target (**y**) is discrete (categorical)\n",
    "- For loss function, cross-entropy is used and for evaluation metric, accuracy is commonly used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "- Breast cancer dataset has total 569 data instances (212 malign, 357 benign instances)\n",
    "- 30 attributes (features) to predict the binary class (M/B)\n",
    "- Doc: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer_data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = breast_cancer_data.data\n",
    "y_data = breast_cancer_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.3, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(398,)\n",
      "(171, 30)\n",
      "(171,)\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10, input_shape=(30,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd=optimizers.SGD(learning_rate=0.01, momentum=0.0)\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 541\n",
      "Trainable params: 541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 398 samples\n",
      "Epoch 1/100\n",
      "398/398 [==============================] - 1s 2ms/sample - loss: 13.5667 - acc: 0.5804\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 0s 139us/sample - loss: 0.6864 - acc: 0.6055\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 0s 99us/sample - loss: 0.6831 - acc: 0.6055\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 0s 98us/sample - loss: 0.6805 - acc: 0.6055\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 0s 116us/sample - loss: 0.6784 - acc: 0.6055\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 0s 147us/sample - loss: 0.6764 - acc: 0.6055\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.6697 - acc: 0.633 - 0s 124us/sample - loss: 0.6755 - acc: 0.6055\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 0s 163us/sample - loss: 0.6745 - acc: 0.6055\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 0s 151us/sample - loss: 0.6735 - acc: 0.6055\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 0s 101us/sample - loss: 0.6732 - acc: 0.6055\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 0s 98us/sample - loss: 0.6727 - acc: 0.6055\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 0s 98us/sample - loss: 0.6723 - acc: 0.6055\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 0s 103us/sample - loss: 0.6720 - acc: 0.6055\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 0s 132us/sample - loss: 0.6717 - acc: 0.6055\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 0s 101us/sample - loss: 0.6716 - acc: 0.6055\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 0s 118us/sample - loss: 0.6714 - acc: 0.6055\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 0s 81us/sample - loss: 0.6712 - acc: 0.6055\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 0s 128us/sample - loss: 0.6711 - acc: 0.6055\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 0s 138us/sample - loss: 0.6712 - acc: 0.6055\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 0s 86us/sample - loss: 0.6712 - acc: 0.6055\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 0s 102us/sample - loss: 0.6711 - acc: 0.6055\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 0s 99us/sample - loss: 0.6711 - acc: 0.6055\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 0s 198us/sample - loss: 0.6710 - acc: 0.6055\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 0s 132us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 0s 102us/sample - loss: 0.6710 - acc: 0.6055\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 0s 106us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 0s 105us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 0s 120us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 0s 130us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 0s 114us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 0s 100us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 0s 93us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 0s 111us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 0s 128us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 0s 133us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 0s 152us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 0s 130us/sample - loss: 0.6710 - acc: 0.6055\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 0s 155us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 0s 127us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 0s 181us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 0s 98us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 0s 145us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 0s 93us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.6587 - acc: 0.633 - 0s 155us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 0s 266us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - 0s 99us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 0s 110us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 0s 124us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 0s 209us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 0s 98us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 0s 132us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 0s 85us/sample - loss: 0.6710 - acc: 0.6055\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 0s 79us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 0s 123us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 0s 99us/sample - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 0s 110us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 0s 121us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 0s 101us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 0s 114us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 0s 85us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 0s 112us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 0s 68us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 0s 127us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 0s 108us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 0s 106us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 0s 102us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 0s 114us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 0s 94us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 0s 88us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 0s 98us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 0s 101us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 0s 87us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 0s 90us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 0s 97us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 0s 132us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 0s 102us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 0s 96us/sample - loss: 0.6707 - acc: 0.6055\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 0s 126us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 0s 121us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 0s 87us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398/398 [==============================] - 0s 81us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 0s 88us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 0s 72us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 84/100\n",
      "398/398 [==============================] - 0s 73us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 0s 68us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 0s 67us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 0s 75us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 0s 86us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 0s 73us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 0s 80us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 0s 86us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 0s 84us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 0s 89us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 0s 113us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 0s 71us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - 0s 69us/sample - loss: 0.6709 - acc: 0.6055\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 0s 72us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 0s 66us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 0s 67us/sample - loss: 0.6708 - acc: 0.6055\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 0s 71us/sample - loss: 0.6708 - acc: 0.6055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13e9c5ba8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=30, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 531us/sample - loss: 0.6482 - acc: 0.6784\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6390235424041748, 0.67836255]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 MLP Advanced\n",
    "\n",
    "- Weight Initialization\n",
    "- Nonlinearity (Activation function)\n",
    "- Optimizers\n",
    "- Batch Normalization\n",
    "- Dropout (Regularization)\n",
    "- Model Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Weight Initialization\n",
    "- Changing weight initialization scheme can significantly improve training of the model by preventing vanishing gradient problem up to some degree\n",
    "- He normal or Xavier normal initialization schemes are SOTA at the moment\n",
    "- Doc: https://keras.io/initializers/\n",
    "\n",
    "#### - Nonlinearity (Activation function)\n",
    "- Sigmoid functions suffer from gradient vanishing problem, making training slower\n",
    "- There are many choices apart from sigmoid and tanh; try many of them!\n",
    "    - **'relu'** (rectified linear unit) is one of the most popular ones\n",
    "    - **'selu'** (scaled exponential linear unit) is one of the most recent ones\n",
    "- Doc: https://keras.io/activations/\n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/nn1/sigmoid.jpeg\" style=\"width: 400px\"/>\n",
    "<center> **Sigmoid Activation Function** </center>\n",
    "<img src=\"http://cs231n.github.io/assets/nn1/relu.jpeg\" style=\"width: 400px\"/>\n",
    "<center> **Relu Activation Function** </center>\n",
    "\n",
    "#### - Optimizers\n",
    "- Many variants of SGD are proposed and employed nowadays\n",
    "- One of the most popular ones are Adam (Adaptive Moment Estimation)\n",
    "- Doc: https://keras.io/optimizers/\n",
    "\n",
    "<img src=\"http://cs231n.github.io/assets/nn3/opt2.gif\" style=\"width: 400px\"/>\n",
    "<br><center> **Relative convergence speed of different optimizers** </center></br>\n",
    "\n",
    "#### - Batch Normalization\n",
    "- Batch Normalization, one of the methods to prevent the \"internal covariance shift\" problem, has proven to be highly effective\n",
    "- Normalize each mini-batch before nonlinearity\n",
    "- Doc: https://keras.io/layers/normalization/\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/torch/torch.github.io/master/blog/_posts/images/resnets_modelvariants.png\" style=\"width: 500px\"/>\n",
    "\n",
    "<br> Batch normalization layer is usually inserted after dense/convolution and before nonlinearity\n",
    "\n",
    "#### - Dropout (Regularization)\n",
    "- Dropout is one of powerful ways to prevent overfitting\n",
    "- The idea is simple. It is disconnecting some (randomly selected) neurons in each layer\n",
    "- The probability of each neuron to be disconnected, namely 'Dropout rate', has to be designated\n",
    "- Doc: https://keras.io/layers/core/#dropout\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/lecture29-convolutionalneuralnetworks-visionspring2015-150504114140-conversion-gate02/95/lecture-29-convolutional-neural-networks-computer-vision-spring2015-62-638.jpg?cb=1430740006\" style=\"width: 500px\"/>\n",
    "\n",
    "#### - Model Ensemble\n",
    "- Model ensemble is a reliable and promising way to boost performance of the model\n",
    "- Usually create 8 to 10 independent networks and merge their results\n",
    "- Here, we resort to scikit-learn API, **VotingClassifier**\n",
    "- Doc: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Classification Task (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "- MNIST: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  5\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[0])      # show first number in the train set\n",
    "plt.show()\n",
    "print('label: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  7\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_test[0])     # show first number in test set\n",
    "plt.show()\n",
    "print('label: ', y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# reshaping X data: (n, 28, 28) => (n, 784)\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting y data into categorical (one-hot encoding)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "y_train[0]  #correspoonding to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_shape=(784,), kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    \n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    \n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    \n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    \n",
    "    model.add(Dense(10, kernel_initializer='he_normal'))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam=optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizers=adam, loss='categorical_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 48,210\n",
      "Trainable params: 47,810\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_model = mlp_model()\n",
    "\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = mlp_model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=0, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'epochs': 100,\n",
       " 'steps': 1313,\n",
       " 'samples': 42000,\n",
       " 'verbose': 0,\n",
       " 'do_validation': True,\n",
       " 'metrics': ['loss', 'acc', 'val_loss', 'val_acc']}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc'] [0.0964179709388176, 0.9723]\n"
     ]
    }
   ],
   "source": [
    "test_results = mlp_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(mlp_model.metrics_names, test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert back from one-hot-encoded to categorical numbers for ensemble classifire\n",
    "y_train = y_train.argmax(axis=1)\n",
    "y_test = y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 5 models to ensemble\n",
    "model1 = KerasClassifier(build_fn=mlp_model, batch_size=32, epochs=100)\n",
    "model2 = KerasClassifier(build_fn=mlp_model, batch_size=32, epochs=100)\n",
    "model3 = KerasClassifier(build_fn=mlp_model, batch_size=32, epochs=100)\n",
    "model4 = KerasClassifier(build_fn=mlp_model, batch_size=32, epochs=100)\n",
    "model5 = KerasClassifier(build_fn=mlp_model, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.7216 - acc: 0.7781\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4300 - acc: 0.8768\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.3742 - acc: 0.8950\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.3441 - acc: 0.9031\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.3240 - acc: 0.9108\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.3066 - acc: 0.9140\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2982 - acc: 0.9173\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2909 - acc: 0.9205\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.2737 - acc: 0.9255\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.2769 - acc: 0.9233\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.2702 - acc: 0.9271\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.2655 - acc: 0.9283\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.2642 - acc: 0.9284\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.2598 - acc: 0.9291\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.2570 - acc: 0.9308\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2562 - acc: 0.9298\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.2479 - acc: 0.9334\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2492 - acc: 0.9314\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.2449 - acc: 0.9338\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.2465 - acc: 0.93251s \n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2409 - acc: 0.9345\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.2391 - acc: 0.9354\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.2405 - acc: 0.9342\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.2362 - acc: 0.9354\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.2378 - acc: 0.9355\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2290 - acc: 0.9363\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2304 - acc: 0.93811s - loss: 0.2295 - acc: 0.9 - ETA: 1s \n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2344 - acc: 0.9352\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2281 - acc: 0.9373\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2289 - acc: 0.9368\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2243 - acc: 0.9388\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2205 - acc: 0.9395\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2216 - acc: 0.9384\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2260 - acc: 0.9386\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2121 - acc: 0.9408\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2184 - acc: 0.9406\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.2184 - acc: 0.9401\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2119 - acc: 0.9421\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2165 - acc: 0.9401\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2102 - acc: 0.9420\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2086 - acc: 0.9432\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2168 - acc: 0.9417\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2136 - acc: 0.9410\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2112 - acc: 0.9425\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2059 - acc: 0.9428\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2023 - acc: 0.9433\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2058 - acc: 0.9435\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2028 - acc: 0.9440\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2050 - acc: 0.9434\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.2051 - acc: 0.9431\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2055 - acc: 0.94351s - \n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2045 - acc: 0.9441\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2061 - acc: 0.9436\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2030 - acc: 0.9451\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2020 - acc: 0.9443\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1989 - acc: 0.9452\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2011 - acc: 0.9458\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1982 - acc: 0.9459\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1996 - acc: 0.9452\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1965 - acc: 0.9460\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2017 - acc: 0.9443\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2013 - acc: 0.94520s - loss: 0.2015 -\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1978 - acc: 0.9462\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1949 - acc: 0.9468\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2007 - acc: 0.9457\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1972 - acc: 0.9459\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2023 - acc: 0.9445\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1953 - acc: 0.9463\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1974 - acc: 0.9463\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1977 - acc: 0.9457\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1899 - acc: 0.9473\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1948 - acc: 0.9468\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1946 - acc: 0.9477\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.1921 - acc: 0.9463\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1929 - acc: 0.9474\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.1975 - acc: 0.9465\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1919 - acc: 0.9466\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1922 - acc: 0.9477\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1923 - acc: 0.9473\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1857 - acc: 0.9494\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1941 - acc: 0.9470\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1935 - acc: 0.9470\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1874 - acc: 0.9481\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1929 - acc: 0.9478\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1892 - acc: 0.9474\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1924 - acc: 0.94740s - loss: 0.1939\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1833 - acc: 0.9486\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1954 - acc: 0.9461\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1852 - acc: 0.9495\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1922 - acc: 0.9476\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1892 - acc: 0.9478\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1842 - acc: 0.9490\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1934 - acc: 0.9470\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1866 - acc: 0.9492\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1921 - acc: 0.9474\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1913 - acc: 0.9472\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1842 - acc: 0.9484\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1843 - acc: 0.9489\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1902 - acc: 0.9487\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1899 - acc: 0.9480\n",
      "Train on 60000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.7136 - acc: 0.7846\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.4365 - acc: 0.8769\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3776 - acc: 0.8943\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.3382 - acc: 0.9056\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.3186 - acc: 0.9125\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.3057 - acc: 0.9155\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2946 - acc: 0.9184\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2861 - acc: 0.9222\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2717 - acc: 0.9253\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2679 - acc: 0.9278\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2682 - acc: 0.9254\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2617 - acc: 0.9295\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2532 - acc: 0.9301\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2491 - acc: 0.9316\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2513 - acc: 0.9309\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2475 - acc: 0.9329\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2427 - acc: 0.9340\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2437 - acc: 0.9354\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2391 - acc: 0.9347\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2416 - acc: 0.9340\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.2343 - acc: 0.9362\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2356 - acc: 0.9365\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.2348 - acc: 0.9363\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2386 - acc: 0.9355\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2351 - acc: 0.9371\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2302 - acc: 0.9377\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2285 - acc: 0.9380\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2281 - acc: 0.9385\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2250 - acc: 0.9391\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2254 - acc: 0.9393\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2223 - acc: 0.9393\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2251 - acc: 0.9392\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.2180 - acc: 0.9405\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2217 - acc: 0.9394\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2164 - acc: 0.9403\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2151 - acc: 0.9421\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2144 - acc: 0.9414\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2191 - acc: 0.9405\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2134 - acc: 0.9425\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2157 - acc: 0.9409\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.2154 - acc: 0.9404\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.2175 - acc: 0.9408\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2137 - acc: 0.9414\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2090 - acc: 0.9430\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2102 - acc: 0.9429\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2148 - acc: 0.9423\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2089 - acc: 0.9421\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.2044 - acc: 0.9446\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2079 - acc: 0.9444\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2068 - acc: 0.9439\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2122 - acc: 0.9434\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2039 - acc: 0.9441\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2040 - acc: 0.9449\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.2059 - acc: 0.9438\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.2091 - acc: 0.9437\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2032 - acc: 0.9446\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2027 - acc: 0.9449\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2008 - acc: 0.9454\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2028 - acc: 0.9442\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1985 - acc: 0.9454\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2032 - acc: 0.9446\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2007 - acc: 0.9449\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1989 - acc: 0.9456\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1999 - acc: 0.9450\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1993 - acc: 0.9454\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2023 - acc: 0.9443\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1984 - acc: 0.9466\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.1984 - acc: 0.9453\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1976 - acc: 0.9464\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1963 - acc: 0.9465\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1948 - acc: 0.9463\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1988 - acc: 0.9454\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1922 - acc: 0.9478\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2001 - acc: 0.9449\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1992 - acc: 0.9459\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1925 - acc: 0.9472\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1959 - acc: 0.9461\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1903 - acc: 0.9475\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1922 - acc: 0.9472\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1956 - acc: 0.9471\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1931 - acc: 0.9473\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1931 - acc: 0.9474\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1918 - acc: 0.9487\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1982 - acc: 0.9459\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1932 - acc: 0.9479\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1939 - acc: 0.9483\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1913 - acc: 0.9490\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1937 - acc: 0.9463\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1957 - acc: 0.9463\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1951 - acc: 0.9472\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1918 - acc: 0.9471\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1959 - acc: 0.9462\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1932 - acc: 0.9474\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1905 - acc: 0.9474\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.1911 - acc: 0.9484\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1901 - acc: 0.9483\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1935 - acc: 0.9470\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1896 - acc: 0.94840s - loss: 0.1906 - acc:\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1912 - acc: 0.9471\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1977 - acc: 0.9465\n",
      "Train on 60000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.7226 - acc: 0.7796\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4359 - acc: 0.8767\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.3797 - acc: 0.8943\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.3488 - acc: 0.9031\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.3249 - acc: 0.9093\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.3098 - acc: 0.9150\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.3004 - acc: 0.9169\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2912 - acc: 0.9194\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2807 - acc: 0.9229\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2782 - acc: 0.9239\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2704 - acc: 0.9263\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2646 - acc: 0.9271\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2563 - acc: 0.9298\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2602 - acc: 0.9297\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2545 - acc: 0.9298\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2502 - acc: 0.9311\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2479 - acc: 0.9315\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2457 - acc: 0.9323\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2434 - acc: 0.9336\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2403 - acc: 0.9338\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2376 - acc: 0.93540s - loss: 0.2360 -\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2418 - acc: 0.9342\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2400 - acc: 0.9347\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2401 - acc: 0.9356\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2375 - acc: 0.9355\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2297 - acc: 0.9375\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2304 - acc: 0.9388\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2291 - acc: 0.9367\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2329 - acc: 0.9376\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2194 - acc: 0.9401\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2229 - acc: 0.9397\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2259 - acc: 0.9374\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2260 - acc: 0.9382\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2231 - acc: 0.9396\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2212 - acc: 0.9402\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.2210 - acc: 0.9391\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.2202 - acc: 0.9397\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.2153 - acc: 0.9407\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.2159 - acc: 0.9410\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1815s 30ms/sample - loss: 0.2180 - acc: 0.9404:15 - loss: 0.\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 8s 136us/sample - loss: 0.2152 - acc: 0.9410\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 7s 111us/sample - loss: 0.2125 - acc: 0.9412\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2160 - acc: 0.9419\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.2119 - acc: 0.9417\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 7s 116us/sample - loss: 0.2116 - acc: 0.9420\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2143 - acc: 0.9408\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2087 - acc: 0.9428\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.2066 - acc: 0.9430\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2134 - acc: 0.9414\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.2097 - acc: 0.9435\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2064 - acc: 0.9436s - loss: 0.2064 - acc: 0.\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2015 - acc: 0.9442\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.2033 - acc: 0.9439\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.2029 - acc: 0.9440\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.2096 - acc: 0.9427\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.2045 - acc: 0.9439\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2074 - acc: 0.9422\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2037 - acc: 0.9434\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2030 - acc: 0.9436\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.1996 - acc: 0.9454\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1963 - acc: 0.9455\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2021 - acc: 0.9452\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.2039 - acc: 0.9440\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2008 - acc: 0.9434\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2017 - acc: 0.9446\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2000 - acc: 0.9446\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.2012 - acc: 0.94524s \n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.1990 - acc: 0.9455\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1965 - acc: 0.9459\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2001 - acc: 0.9454\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1993 - acc: 0.9466\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1997 - acc: 0.9449\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.1951 - acc: 0.9471\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2036 - acc: 0.9443\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1963 - acc: 0.9460\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1949 - acc: 0.9473\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.1974 - acc: 0.9458\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1943 - acc: 0.9475\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 11s 176us/sample - loss: 0.2001 - acc: 0.9462\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 10s 162us/sample - loss: 0.1962 - acc: 0.9460\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 8s 136us/sample - loss: 0.1927 - acc: 0.9465\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 9s 147us/sample - loss: 0.1971 - acc: 0.9454s - loss: \n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 0.1878 - acc: 0.9482\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1940 - acc: 0.9463\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.1914 - acc: 0.9482\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.1895 - acc: 0.9474\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.1875 - acc: 0.9484\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.1948 - acc: 0.9471\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.1903 - acc: 0.9480\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 7s 118us/sample - loss: 0.1915 - acc: 0.9480\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.1948 - acc: 0.9462\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.1946 - acc: 0.9468\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.1895 - acc: 0.9476\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.1943 - acc: 0.9475\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.1947 - acc: 0.9470\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 7s 112us/sample - loss: 0.1903 - acc: 0.9477\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.1871 - acc: 0.9485\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.1926 - acc: 0.9478\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.1872 - acc: 0.9484\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.1859 - acc: 0.9485\n",
      "Train on 60000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 7s 124us/sample - loss: 0.7224 - acc: 0.7811\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.4294 - acc: 0.8786\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.3732 - acc: 0.8953\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.3474 - acc: 0.9048\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.3273 - acc: 0.9090\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.3028 - acc: 0.9143\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2974 - acc: 0.9188\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.2862 - acc: 0.9219\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.2773 - acc: 0.9242\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.2735 - acc: 0.9246\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2731 - acc: 0.9241\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2620 - acc: 0.9276\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2574 - acc: 0.9305\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2570 - acc: 0.9294\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2552 - acc: 0.9297\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.2520 - acc: 0.9316\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 7s 122us/sample - loss: 0.2414 - acc: 0.9330\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.2482 - acc: 0.9313\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2466 - acc: 0.9321\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2425 - acc: 0.9335\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2390 - acc: 0.9347\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2400 - acc: 0.9345\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2359 - acc: 0.9363\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2296 - acc: 0.9363\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.2355 - acc: 0.9355\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2269 - acc: 0.93790s - loss: 0.2281 - acc: 0.9\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2297 - acc: 0.9379\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.2225 - acc: 0.9388s - loss: 0.2229 - acc: 0.\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2208 - acc: 0.9396\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2233 - acc: 0.9387\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.2230 - acc: 0.9389\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.2229 - acc: 0.9392\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.2240 - acc: 0.9376\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.2166 - acc: 0.9405\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2140 - acc: 0.9416\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2135 - acc: 0.9418\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2116 - acc: 0.9422\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 5s 92us/sample - loss: 0.2171 - acc: 0.9399\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2136 - acc: 0.9415\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.2100 - acc: 0.9424\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.2100 - acc: 0.9422\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 0.2129 - acc: 0.9427\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2139 - acc: 0.9421\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.2101 - acc: 0.9428\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2114 - acc: 0.9412s - loss: 0.\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.2064 - acc: 0.9427\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.2070 - acc: 0.9440\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.2069 - acc: 0.9443\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2057 - acc: 0.9435\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.2026 - acc: 0.94430s - loss: 0.203\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.2044 - acc: 0.9449\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.2027 - acc: 0.9449\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2095 - acc: 0.9437\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.2077 - acc: 0.9434\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2012 - acc: 0.9449\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.2002 - acc: 0.9444\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.2022 - acc: 0.9452\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2003 - acc: 0.9458\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.1995 - acc: 0.9449\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.2015 - acc: 0.9454\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.2045 - acc: 0.9442\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2017 - acc: 0.9444\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.1965 - acc: 0.9465\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1980 - acc: 0.9458\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1951 - acc: 0.9462\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.1952 - acc: 0.9460\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1972 - acc: 0.9463\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.1979 - acc: 0.9451\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1990 - acc: 0.9453\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1971 - acc: 0.9453\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1920 - acc: 0.9471\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1948 - acc: 0.9452\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.1930 - acc: 0.9480\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1944 - acc: 0.9460\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1943 - acc: 0.9473\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1936 - acc: 0.9469\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1873 - acc: 0.94841s - l\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1981 - acc: 0.9459\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1957 - acc: 0.9473\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1926 - acc: 0.9469\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1973 - acc: 0.9456\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.1866 - acc: 0.9488\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.1933 - acc: 0.9463\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.1867 - acc: 0.9482\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.1955 - acc: 0.9467\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1932 - acc: 0.9473\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.1909 - acc: 0.9483\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.1959 - acc: 0.9465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.1869 - acc: 0.9487\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1890 - acc: 0.9483\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1867 - acc: 0.9499\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.1946 - acc: 0.9471\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.1872 - acc: 0.9482\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.1933 - acc: 0.9470\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.1889 - acc: 0.9481\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.1899 - acc: 0.9477\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1883 - acc: 0.9492\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.1914 - acc: 0.9474\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1893 - acc: 0.9489\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1885 - acc: 0.9480\n",
      "Train on 60000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.7249 - acc: 0.7821\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.4311 - acc: 0.8766\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 7s 117us/sample - loss: 0.3765 - acc: 0.8934s -\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.3439 - acc: 0.9054\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.3183 - acc: 0.9111\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.3130 - acc: 0.9124\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2971 - acc: 0.9177\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.2827 - acc: 0.9210\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2829 - acc: 0.9213\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.2748 - acc: 0.9244\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.2690 - acc: 0.9260\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2680 - acc: 0.9269\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2636 - acc: 0.9278\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.2576 - acc: 0.9287\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2603 - acc: 0.9287\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.2493 - acc: 0.9321\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2519 - acc: 0.9308\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2475 - acc: 0.9314\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2443 - acc: 0.9326\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2462 - acc: 0.9327\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.2379 - acc: 0.9349\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2382 - acc: 0.9344\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2355 - acc: 0.9361\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2375 - acc: 0.9366\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2343 - acc: 0.9357\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2304 - acc: 0.9355\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.2327 - acc: 0.9368\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.2311 - acc: 0.9368\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2268 - acc: 0.9387\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.2269 - acc: 0.9371\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2217 - acc: 0.9402\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2219 - acc: 0.9384\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2231 - acc: 0.9396\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2181 - acc: 0.9396\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2249 - acc: 0.9377\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.2156 - acc: 0.9408\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2168 - acc: 0.9405\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.2173 - acc: 0.9407\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2174 - acc: 0.9403\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2130 - acc: 0.9427\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2153 - acc: 0.9416\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2152 - acc: 0.9408\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.2142 - acc: 0.9417\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 4s 74us/sample - loss: 0.2095 - acc: 0.9421\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.2130 - acc: 0.9407\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.2121 - acc: 0.9420\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.2082 - acc: 0.9424\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.2091 - acc: 0.9417\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.2090 - acc: 0.9436\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.2100 - acc: 0.9426\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2073 - acc: 0.9436\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2129 - acc: 0.9416\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2072 - acc: 0.9429\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.2086 - acc: 0.9438\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.2017 - acc: 0.9441\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.2022 - acc: 0.9448\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2035 - acc: 0.9438\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.2010 - acc: 0.9446\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2007 - acc: 0.9441\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2017 - acc: 0.9450\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2004 - acc: 0.9451\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2018 - acc: 0.9454\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.1996 - acc: 0.9449\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.1992 - acc: 0.9458\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.1955 - acc: 0.9468\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.2033 - acc: 0.9453\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 6s 94us/sample - loss: 0.2012 - acc: 0.9461\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1978 - acc: 0.9463\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1962 - acc: 0.9470\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2017 - acc: 0.9453\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.1968 - acc: 0.9463\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 8s 132us/sample - loss: 0.1963 - acc: 0.9460\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.1965 - acc: 0.9466\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.1974 - acc: 0.9460\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1940 - acc: 0.9467\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1910 - acc: 0.9464\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1919 - acc: 0.9471\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1959 - acc: 0.9462\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1927 - acc: 0.9468\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1914 - acc: 0.9477\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1912 - acc: 0.9476\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.1913 - acc: 0.9469\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1896 - acc: 0.9462\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1903 - acc: 0.9479\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1907 - acc: 0.9483\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1894 - acc: 0.94750s - loss: 0.18\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1909 - acc: 0.9481\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1924 - acc: 0.9476\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1922 - acc: 0.9475\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1880 - acc: 0.9478\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1893 - acc: 0.94870s - loss: 0.1890 - acc: 0.9\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1929 - acc: 0.9481\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1906 - acc: 0.9477\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1868 - acc: 0.9493\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1934 - acc: 0.9477\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1912 - acc: 0.9475\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1874 - acc: 0.9485\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.1918 - acc: 0.9476\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.1958 - acc: 0.9455\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.1886 - acc: 0.9478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('model1', <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x14ef6ecf8>), ('model2', <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x14ef6ea20>), ('model3', <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x14ef..., ('model5', <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x14ef6eda0>)],\n",
       "         flatten_transform=None, n_jobs=None, voting='soft', weights=None)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_clf = VotingClassifier(estimators=[('model1', model1), ('model2', model2), ('model3', model3), ('model4', model4), ('model5', model5)], \\\n",
    "                    voting='soft')\n",
    "\n",
    "ensemble_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9793"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ensemble_clf.predict(X_test)\n",
    "\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
